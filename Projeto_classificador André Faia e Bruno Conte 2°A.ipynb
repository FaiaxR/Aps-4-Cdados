{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Bruno Conte Paiva\n",
    "\n",
    "Nome: André Faia Vasconcelos Ramos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from IPython.display import display\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "pd.options.display.max_rows = 900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando o arquivo excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo Projeto_excel.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'Projeto_excel.xlsx'\n",
    "\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "    \n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes, neutros e não relevantes do treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_treinamento = pd.read_excel(filename, coverters = {'Treino': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dando nomes aos valores de 'relevância' no treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_treinamento['relevância'] = data_treinamento['relevância'].astype('category')\n",
    "data_treinamento.relevância.cat.categories = ['irrelevante', 'neutro', 'relevante']\n",
    "data_treinamento.relevância.cat = pd.Categorical(data_treinamento.relevância, categories = ['irrelevante', 'neutro', 'relevante'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrando e organizando os tweets do treinamento por 'relevância':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para relevantes:\n",
    "\n",
    "data_treinamento_relevantes = data_treinamento['relevância'] == 'relevante'\n",
    "treinamento_relevantes = data_treinamento.loc[data_treinamento_relevantes, :]\n",
    "\n",
    "\n",
    "#para neutros:\n",
    "\n",
    "data_treinamento_neutros = data_treinamento['relevância'] == 'neutro'\n",
    "treinamento_neutros = data_treinamento.loc[data_treinamento_neutros, :]\n",
    "\n",
    "#para irrelevantes:\n",
    "\n",
    "data_treinamento_irrelevantes = data_treinamento['relevância'] == 'irrelevante'\n",
    "treinamento_irrelevantes = data_treinamento.loc[data_treinamento_irrelevantes, :]\n",
    "\n",
    "#todas as relevâncias:\n",
    "\n",
    "lista_treinamento = [treinamento_irrelevantes, treinamento_neutros, treinamento_relevantes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes, neutros e não relevantes do teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_teste = pd.read_excel(filename, sheet_name = 'Teste', coverters = {'Test': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dando nomes aos valores de 'relevância' no teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_teste['relevância'] = data_teste['relevância'].astype('category')\n",
    "data_teste.relevância.cat.categories = ['irrelevante', 'neutro', 'relevante']\n",
    "data_teste.relevância.cat = pd.Categorical(data_teste.relevância, categories = ['irrelevante', 'neutro', 'relevante'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrando e organizando os tweets do teste por 'relevância':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para relevantes:\n",
    "\n",
    "data_teste_relevantes = data_teste['relevância'] == 'relevante'\n",
    "teste_relevantes = data_teste.loc[data_teste_relevantes, :]\n",
    "\n",
    "#para neutros:\n",
    "\n",
    "data_teste_neutros = data_teste['relevância'] == 'neutro'\n",
    "teste_neutros = data_teste.loc[data_teste_neutros, :]\n",
    "\n",
    "#para irrelevantes:\n",
    "\n",
    "data_teste_irrelevantes = data_teste['relevância'] == 'irrelevante'\n",
    "teste_irrelevantes = data_teste.loc[data_teste_irrelevantes, :]\n",
    "\n",
    "lista_teste = [data_teste_irrelevantes, data_teste_neutros, data_teste_relevantes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "O produto escolhido foi o iPhone que é um smartphone da marca Apple, de relevância mundial. A classificação foi feita a partir da presença ou não de comentários que falam sobre o produto, sem relevar a marca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Critérios de classificação dos tweets:\n",
    "\n",
    "*\"irrelevantes\" : Tweets que não falam sobre o produto e suas funcionalidades, mas citam a marca.\n",
    "\n",
    "*\"neutros\" : Tweets que falam sobre a marca, porém nada relevante.\n",
    "\n",
    "*\"relevantes\": Tweets que agregam algo à marca, como sugestões, críticas, entre outros.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Criando as funções de clean-up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que realizará o primeiro cleanup, trocando sinais de pontuação por espaços:\n",
    "def cleanup(textos):\n",
    "    pontuação = '[!-.:?;@]'\n",
    "    pattern = re.compile(pontuação)\n",
    "    text_subbed = re.sub(pattern,'', textos)\n",
    "\n",
    "    return text_subbed\n",
    "\n",
    "#função que realizará a remoção dos arrobas('@'):\n",
    "\n",
    "def arroba(lista_arroba):\n",
    "    arroba = '@'\n",
    "    for l in lista_arroba:\n",
    "        if arroba in l:\n",
    "            lista_arroba.replace(arroba, \"\")\n",
    "    \n",
    "    return lista_arroba\n",
    "\n",
    "#função que realizará a remoção de strings de links:\n",
    "\n",
    "def links(lista_links):\n",
    "    link = 'http'\n",
    "    for l in lista_links:\n",
    "        if link in l:\n",
    "            lista_links.replace(link, \"\")\n",
    "    \n",
    "    return lista_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando os cleanups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removendo sinais de pontuação:\n",
    "\n",
    "textos_sinais = []\n",
    "lista_textos_filtrados = []\n",
    "for df in lista_treinamento:\n",
    "    lista_sinais = df['Treino'].values.tolist()\n",
    "    for t in lista_sinais:\n",
    "        lista_textos_filtrados = cleanup(t)\n",
    "        textos_sinais.append(lista_textos_filtrados)\n",
    "\n",
    "#removendo arrobas:\n",
    "\n",
    "textos_arrobas = []\n",
    "lista_textos_filtrados1 = []\n",
    "for t in textos_sinais:\n",
    "    lista_arrobas = df\n",
    "    for df in lista_arrobas:\n",
    "        lista_textos_filtrados = arroba(df)\n",
    "        textos_arrobas.append(lista_textos_filtrados1)\n",
    "    \n",
    "#removendo links:\n",
    "\n",
    "textos_links = []\n",
    "lista_textos_filtrados2 = []\n",
    "for t in textos_arrobas:\n",
    "    lista_links = df\n",
    "    for df in lista_links:\n",
    "        lista_textos_filtrados1 = links(df)\n",
    "        textos_links.append(lista_textos_filtrados2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciando os cálculos das probabilidades no treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cálculo das probabilidades no treinamento:\n",
    "\n",
    "lista_relevâncias = data_treinamento['relevância'].value_counts(True, sort = False)\n",
    "\n",
    "#probabilidade de ser irrelevante:\n",
    "P_I = lista_relevâncias[0]\n",
    "\n",
    "#probabilidade de ser neutro:\n",
    "P_N = lista_relevâncias[1]\n",
    "\n",
    "#probabilidade de ser relevante:\n",
    "P_R = lista_relevâncias[2]\n",
    "\n",
    "#probabilidade de cada grau de relevância:\n",
    "\n",
    "lista_relevâncias = [P_I, P_N, P_R]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listas separadas:\n",
    "\n",
    "palavras_treinamento_I = pd.Series(lista_textos_filtrados2).value_counts()\n",
    "palavras_treinamento_N = pd.Series(lista_textos_filtrados2).value_counts()\n",
    "palavras_treinamento_R = pd.Series(lista_textos_filtrados2).value_counts()\n",
    "\n",
    "dicionario_palavras = [palavras_treinamento_I, palavras_treinamento_N, palavras_treinamento_R]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função do classificador Naive Bayes:\n",
    "\n",
    "lista = []\n",
    "dicionario = {}\n",
    "dicionario2= {}\n",
    "lista_probabilidades = []\n",
    "    \n",
    "#definindo as variáveis e colocando seus respectivos valores:\n",
    "    \n",
    "a = 1*10**-5\n",
    "b = 0\n",
    "\n",
    "def Classificador(texto):\n",
    "    texto_filtrado = cleanup(texto)\n",
    "    lista = []\n",
    "    for d in dicionario_palavras:\n",
    "        dicionario = {}\n",
    "        for p in texto_filtrado:\n",
    "            if p in dicionario:\n",
    "                dicionario2[p] = dicionario[p]\n",
    "            else:\n",
    "                dicionario2[p] = 0\n",
    "        lista.append(pd.Series(dicionario2))\n",
    "        \n",
    "    #listas para cada grau de relevância:\n",
    "\n",
    "    I = lista[0]\n",
    "    N = lista [1]\n",
    "    R = lista [2]\n",
    "\n",
    "    Relevância = [I, N, R]\n",
    "\n",
    "    valor_maximo = 0\n",
    "    \n",
    "    for c in range(0, len(lista_probabilidades)):\n",
    "        if lista_probabilidades[valor_maximo] <= lista_probabilidades[c]:\n",
    "            valor_maximo = c\n",
    "            \n",
    "    if valor_maximo == 0:\n",
    "        nb_relevância = \"irrelevante\"\n",
    "\n",
    "    elif valor_maximo == 1:\n",
    "        nb_relevância = \"neutro\"\n",
    "\n",
    "    else:\n",
    "        nb_relevância = \"relevante\"\n",
    "        \n",
    "    return nb_relevância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando o classificador, montando tabelas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalizando classificador Naive Bayes:\n",
    "\n",
    "naive_bayes = []\n",
    "\n",
    "for x in data_treinamento[\"Treino\"]:\n",
    "    naive_bayes.append(Classificador(x))\n",
    "\n",
    "data_treinamento[\"RELEVÂNCIA\"] = naive_bayes\n",
    "\n",
    "#Iniciando as comparações:\n",
    "\n",
    "RELEVÂNCIA_vs_relevância = pd.crosstab(data_treinamento.relevância, data_treinamento.RELEVÂNCIA, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
